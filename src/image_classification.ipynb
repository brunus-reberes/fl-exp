{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import gp, creator, base, tools, algorithms\n",
    "import operator\n",
    "import random\n",
    "import math\n",
    "import numpy\n",
    "from mnist import MNIST\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.ndimage as scipy \n",
    "import random\n",
    "import skimage.feature as skimage\n",
    "from skimage.measure import block_reduce \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GENERATIONS = 50\n",
    "POPULATION_SIZE = 500\n",
    "CROSSOVER_RATE = 0.8\n",
    "MUTATION_RATE = 0.19\n",
    "ELITIIM_RATE = 0.01\n",
    "TOURNAMENT_SIZE = 7\n",
    "TREE_DEPTH = 2, 6\n",
    "MAX_TREE_DEPTH = 8\n",
    "HOF_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "dataset = MNIST('dataset', return_type='numpy')\n",
    "train_images, train_labels = dataset.load_training()\n",
    "test_images, test_labels = dataset.load_testing()\n",
    "train_images = train_images.reshape(len(train_images),28,28).astype('uint8') / 255\n",
    "test_images = test_images.reshape(len(test_images),28,28).astype('uint8') / 255\n",
    "train_set = train_images[:1000]\n",
    "test_set = test_images[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = train_images[0]\n",
    "plt.imshow(src)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gau(img, sigma):\n",
    "    return cv.GaussianBlur(img, (3,3), sigma)\n",
    "dst = gau(src, 1.)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_derivates_filter(img, sigma, order1, order2):\n",
    "    return scipy.gaussian_filter(img, sigma, (order1, order2))\n",
    "dst = gaussian_derivates_filter(src, 1, 1, 0)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabor_filter(img, theta, lambd): \n",
    "    kernel = cv.getGaborKernel((3,3), 10, theta, lambd, 0)\n",
    "    return cv.filter2D(img, cv.CV_64F, kernel)\n",
    "dst = gabor_filter(src, 1, 1)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dst = cv.Laplacian(src, cv.CV_64F)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = scipy.gaussian_laplace(src, 1)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = scipy.sobel(src)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = scipy.median_filter(src, 3)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv.blur(src, (3,3))\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = scipy.minimum_filter(src, 3)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = scipy.maximum_filter(src, 3)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = skimage.local_binary_pattern(src, 8, 1.5)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp(img, show=False):\n",
    "    dst = skimage.local_binary_pattern(img, 8, 1.5, method=\"uniform\")\n",
    "    if show:\n",
    "        plt.imshow(dst)\n",
    "        plt.show()\n",
    "    (hist, _) = np.histogram(dst.ravel(),\n",
    "        bins=np.arange(0, 8 + 3),\n",
    "        range=(0, 8 + 2))\n",
    "    # normalize the histogram\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)\n",
    "    return hist\n",
    "print(lbp(src, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog(img, f):\n",
    "    vec, res = skimage.hog(img, visualize=True, feature_vector=True)\n",
    "    return res if f else vec\n",
    "print(hog(src, False))\n",
    "dst = hog(src, True)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv.addWeighted(src, 0.1, train_images[1], 0.1, 0)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subWeighted(src1, alpha, src2, beta):\n",
    "    return cv.addWeighted(src1, alpha, src2, -beta, 0)\n",
    "dst = subWeighted(src, 0.1, train_images[1], 0.1)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = np.vectorize(lambda x: 0 if x<0 else x)\n",
    "dst = relu(src)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt = np.vectorize(lambda x: 1 if x<0 else math.sqrt(x))\n",
    "dst = sqrt(src)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max pooling\n",
    "def maxp(img, k1, k2):\n",
    "    return block_reduce(img, (k1,k2), np.max)\n",
    "dst = maxp(src, 2,2)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift(img, show=False):\n",
    "    sift = cv.SIFT_create(128)\n",
    "    kp, des = sift.detectAndCompute((img*255).astype(np.uint8), None)\n",
    "    if show:\n",
    "        plt.imshow(cv.drawKeypoints((img*255).astype(np.uint8),kp,(img*255).astype(np.uint8)))\n",
    "        plt.show()\n",
    "    \n",
    "    return des.ravel()\n",
    "print(sift(src, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root(*v: np.ndarray):\n",
    "    return np.concatenate(v)\n",
    "print(root(hog(src, False), lbp(src), sift(src)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feacon(*imgs: np.ndarray):\n",
    "    return np.concatenate(imgs).ravel()\n",
    "src2 = cv.addWeighted(src, 0.1, train_images[1], 0.1, 0)\n",
    "print(feacon(src, src2, train_images[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = type('sigma', (), {})\n",
    "order = type('order', (), {})\n",
    "theta = type('theta', (), {})\n",
    "lambd = type('lambd', (), {})\n",
    "n_type = type('n', (), {})\n",
    "kernel = type('kernel', (), {})\n",
    "vector = type('vector', (), {})\n",
    "output = type(\"output\", (), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"lap\", cv.Laplacian, ddepth=cv.CV_64F)\n",
    "toolbox.register(\"log1\", scipy.gaussian_laplace, sigma=1)\n",
    "toolbox.register(\"log2\", scipy.gaussian_laplace, sigma=2)\n",
    "toolbox.register(\"sobel\", cv.Sobel, ddepth=cv.CV_64F, dx=1, dy=1)\n",
    "toolbox.register(\"sobelx\", cv.Sobel, ddepth=cv.CV_64F, dx=1, dy=0)\n",
    "toolbox.register(\"sobely\", cv.Sobel, ddepth=cv.CV_64F, dx=0, dy=1)\n",
    "toolbox.register(\"med\", scipy.median_filter, size=3)\n",
    "toolbox.register(\"mean\", cv.blur, ksize=(3,3))\n",
    "toolbox.register(\"min\", scipy.minimum_filter, size=3)\n",
    "toolbox.register(\"max\", scipy.maximum_filter, size=3)\n",
    "toolbox.register(\"LBP_F\", skimage.local_binary_pattern, P=8, R=1.5)\n",
    "toolbox.register(\"HOG_F\", hog, f=True)\n",
    "toolbox.register(\"HOG\", hog, f=False)\n",
    "toolbox.register(\"W_add\", cv.addWeighted, gamma=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feacon(toolbox.HOG(src), sift(src), lbp(src), lbp(src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset = gp.PrimitiveSetTyped(\"main\", [np.ndarray], output, prefix = \"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering functions\n",
    "pset.addPrimitive(gau, [np.ndarray, sigma], np.ndarray, \"Gau\")\n",
    "pset.addPrimitive(gaussian_derivates_filter, [np.ndarray, sigma, order, order], np.ndarray, \"GauD\")\n",
    "pset.addPrimitive(gabor_filter, [np.ndarray, theta, lambd], np.ndarray, \"Gabor\")\n",
    "pset.addPrimitive(toolbox.lap, [np.ndarray], np.ndarray, \"Lap\")\n",
    "pset.addPrimitive(toolbox.log1, [np.ndarray], np.ndarray, \"LoG1\")\n",
    "pset.addPrimitive(toolbox.log2, [np.ndarray], np.ndarray, \"LoG2\")\n",
    "pset.addPrimitive(toolbox.sobel, [np.ndarray], np.ndarray, \"Sobel\")\n",
    "pset.addPrimitive(toolbox.sobelx, [np.ndarray], np.ndarray, \"SobelX\")\n",
    "pset.addPrimitive(toolbox.sobely, [np.ndarray], np.ndarray, \"SobelY\")\n",
    "pset.addPrimitive(toolbox.med, [np.ndarray], np.ndarray, \"Med\")\n",
    "pset.addPrimitive(toolbox.mean, [np.ndarray], np.ndarray, \"Mean\")\n",
    "pset.addPrimitive(toolbox.min, [np.ndarray], np.ndarray, \"Min\")\n",
    "pset.addPrimitive(toolbox.max, [np.ndarray], np.ndarray, \"Max\")\n",
    "pset.addPrimitive(toolbox.LBP_F, [np.ndarray], np.ndarray, \"LBP_F\")\n",
    "pset.addPrimitive(toolbox.HOG_F, [np.ndarray], np.ndarray, \"HOG_F\")\n",
    "pset.addPrimitive(toolbox.W_add, [np.ndarray, n_type, np.ndarray, n_type], np.ndarray, \"W_Add\")\n",
    "pset.addPrimitive(subWeighted, [np.ndarray, n_type, np.ndarray, n_type], np.ndarray, \"W_Sub\")\n",
    "pset.addPrimitive(relu, [np.ndarray], np.ndarray, \"ReLU\")\n",
    "pset.addPrimitive(sqrt, [np.ndarray], np.ndarray, \"Sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooling functions\n",
    "pset.addPrimitive(maxp, [np.ndarray, kernel, kernel], np.ndarray, \"MaxP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction\n",
    "pset.addPrimitive(sift, [np.ndarray], vector, \"SIFT\")\n",
    "pset.addPrimitive(lbp, [np.ndarray], vector, \"LBP\")\n",
    "pset.addPrimitive(toolbox.HOG, [np.ndarray], vector, \"HOG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenation Functionas\n",
    "pset.addPrimitive(root, [vector, vector], output, \"Root2\")\n",
    "pset.addPrimitive(root, [vector, vector, vector], output, \"Root3\")\n",
    "pset.addPrimitive(root, [vector, vector, vector, vector], output, \"Root4\")\n",
    "pset.addPrimitive(feacon, [np.ndarray, np.ndarray], output, \"FeaCon2\")\n",
    "pset.addPrimitive(feacon, [np.ndarray, np.ndarray, np.ndarray], output, \"FeaCon3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ephemeral Constants\n",
    "pset.addEphemeralConstant(\"sigma\", lambda: random.randint(1, 3), sigma)\n",
    "pset.addEphemeralConstant(\"order\", lambda: random.randint(0, 2), order)\n",
    "pset.addEphemeralConstant(\"theta\", lambda: random.choice([i for i in np.arange(0, 7*math.pi/8, math.pi/8)]), theta)\n",
    "pset.addEphemeralConstant(\"lambda\", lambda: pow(math.sqrt(2), random.randint(0, 4))/(math.pi/2), lambd)\n",
    "pset.addEphemeralConstant(\"n\", lambda: random.random(), n_type)\n",
    "pset.addEphemeralConstant(\"kernel\", lambda: random.randint(1, 4), kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=TREE_DEPTH[0], max_=TREE_DEPTH[1])\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"compile\", gp.compile, pset=pset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalInd(individual):\n",
    "    func = toolbox.compile(expr=individual)\n",
    "    #train\n",
    "    vectors = []\n",
    "    for img in train_set:\n",
    "        temp = func(img)\n",
    "        vectors.append(temp)\n",
    "    minmax = MinMaxScaler()\n",
    "    norm_vectors = minmax.fit_transform(vectors)\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(norm_vectors, train_labels[:len(vectors)])\n",
    "    #test\n",
    "    predictions = svm.predict(test_set)\n",
    "    result = accuracy_score(test_labels[:len(test_set)], predictions)\n",
    "    return result,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = train_set[0]\n",
    "#print(src)\n",
    "#show(relu(toolbox.sobelx(maxp(src, 2, 3))))\n",
    "ind = \"Root3(SIFT(MaxP(W_Sub(Image0, 0.453, Image0, 0.641), 4, 2)), HOG(W_Add(LoG2(Image0), 0.031, W_Sub(ReLU(SobelY(Image0)), 0.9, W_Add(LoG1(Image0), 0.206, GauD(Image0, 2, 0, 1), 0.776), 0.837), 0.837)), HOG(Lap(Image0)))\"\n",
    "ind = \"SIFT(MaxP(W_Sub(Image0, 0.453, Image0, 0.641), 4, 2))\"\n",
    "ind = \"MaxP(W_Sub(Image0, 0.453, Image0, 0.641), 4, 2)\"\n",
    "print(sift(toolbox.compile(ind)(src)))\n",
    "print(evalInd(ind))\n",
    "#print(eval(\"Root2(SIFT(Image0), HOG(SobelX(MaxP(Image0, 2, 3))))\"))\n",
    "#print(eval(\"Root2(HOG(Image0), HOG(LBP_F(Image0)))\"))\n",
    "#print(eval(\"FeaCon3(Mean(W_Sub(LoG1(LoG2(Gabor(Image0, 1.9634954084936207, 2.546479089470326))), Gabor(Sobel(Image0), Sobel(HOG_F(Image0)), HOG_F(Image0)), Image0, HOG_F(Image0))), HOG_F(ReLU(Med(Gau(GauD(Image0, 1, 0, 2), 3)))), Gabor(HOG_F(Gabor(LoG1(Min(Image0)), 0.0, 0.6366197723675814)), Min(Lap(Min(Sobel(Image0)))), Sobel(Lap(Min(GauD(Image0, 3, 1, 0))))))\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = toolbox.individual()\n",
    "print(ind)\n",
    "print(evalInd(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"evaluate\", eval)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=TOURNAMENT_SIZE)\n",
    "toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "toolbox.register(\"expr_mut\", gp.genFull, min_=TREE_DEPTH[0], max_=TREE_DEPTH[1])\n",
    "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
    "\n",
    "toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=8))\n",
    "toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pset.primitives)\n",
    "#print(pset.terminals)\n",
    "tipo = output\n",
    "for prim in pset.primitives[tipo]:  \n",
    "    print(prim.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "random.seed(10)\n",
    "pop = toolbox.population(n=POPULATION_SIZE)\n",
    "hof = tools.HallOfFame(HOF_SIZE)\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", numpy.mean)\n",
    "stats.register(\"std\", numpy.std)\n",
    "stats.register(\"min\", numpy.min)\n",
    "stats.register(\"max\", numpy.max)\n",
    "\n",
    "_, log = algorithms.eaSimple(\n",
    "    pop, \n",
    "    toolbox, \n",
    "    CROSSOVER_RATE, \n",
    "    MUTATION_RATE, \n",
    "    MAX_GENERATIONS, \n",
    "    stats, \n",
    "    halloffame=hof\n",
    "    )\n",
    "print(log)\n",
    "pop, stats, hof"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4184aae088894a3740fc47dfcddf6bb95213e93e54e8cc72e0849571dc8d4493"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
